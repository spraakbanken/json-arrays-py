on:
  push:
    branches:
      - main
name: benchmarks_base

permissions:
  contents: read

env:
  MINIMUM_PYTHON_VERSION: "3.9"
  UV_VERSION: "0.9.1"

jobs:
  benchmark_base_branch:
    name: ubuntu / ${{ matrix.python-version }} / continuous benchmarking with bencher
    strategy:
      max-parallel: 4
      fail-fast: false
      matrix:
        python-version:
          - "3.9"
          - "3.10"
          - "3.11"
          - "3.12"
          - "3.13"
    permissions:
      checks: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@ff7abcd0c3c05ccf6adc123a8cd1fd4fb30fb493 # v5.0.0
        with:
          submodules: true
          persist-credentials: false
      - name: Set up uv
        uses: astral-sh/setup-uv@3259c6206f993105e3a61b142c2d97bf4b9ef83d # 7.1.0
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
      - name: Set up Python ${{ matrix.python-version }}
        id: setup-python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: make dev
      - uses: bencherdev/bencher@d84683bed6747f23f9903a02cd2a70502cee0b8d #v0.5.5
      - name: Track base branch benchmarks with Bencher
        run: |
          source .venv/bin/activate
          bencher run \
          --project json-arrays-py \
          --token '${{ secrets.BENCHER_API_TOKEN }}' \
          --branch main \
          --testbed 'ci-ubuntu-latest-python-${{ matrix.python-version }}' \
          --threshold-measure latency \
          --threshold-test t_test \
          --threshold-max-sample-size 64 \
          --threshold-upper-boundary 0.99 \
          --thresholds-reset \
          --err \
          --adapter python_pytest \
          --file results.json \
          --github-actions '${{ secrets.GITHUB_TOKEN }}' \
          "pytest --benchmark-json results.json benchmarks"
